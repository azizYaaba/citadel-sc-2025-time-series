{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TP — Time Series Foundation Models (Chronos, Moirai, Time-MoE)\n",
        "\n",
        "Ce notebook est conçu pour être exécuté **en local** ou sur **Google Colab**.\n",
        "\n",
        "Objectif : faire un premier TP *hands-on* sur 3 modèles fondationnels pour la prévision de séries temporelles :\n",
        "\n",
        "- **Chronos-2** (Amazon)\n",
        "- **Moirai** via **Uni2TS** (Salesforce)\n",
        "- **Time-MoE** (Mixture-of-Experts)\n",
        "\n",
        "Chaque partie suit la même logique :\n",
        "1) Installer / importer\n",
        "2) Charger une petite série temporelle (format clair)\n",
        "3) Faire une prévision + visualiser\n",
        "\n",
        "> Conseil : sur Colab, activez un GPU (Runtime → Change runtime type → GPU).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# (Optionnel) Infos environnement\n",
        "import sys, platform\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"Platform:\", platform.platform())\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print(\"Torch:\", torch.__version__)\n",
        "    print(\"CUDA available:\", torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "except Exception as e:\n",
        "    print(\"Torch not installed yet:\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Données de démonstration (communes)\n",
        "\n",
        "On utilise une **petite série univariée** (un seul signal) pour aller vite.\n",
        "\n",
        "- En pratique : remplacez `target` par votre colonne cible.\n",
        "- On crée un index temporel (`timestamp`) pour un affichage propre.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Série synthétique simple (tendance + saisonnalité + bruit)\n",
        "T = 400\n",
        "rng = np.random.default_rng(7)\n",
        "idx = pd.date_range(\"2022-01-01\", periods=T, freq=\"H\")\n",
        "\n",
        "trend = np.linspace(0, 4, T)\n",
        "season = 1.2 * np.sin(2 * np.pi * np.arange(T) / 24)\n",
        "noise = 0.35 * rng.standard_normal(T)\n",
        "\n",
        "y = 10 + trend + season + noise\n",
        "\n",
        "df = pd.DataFrame({\"timestamp\": idx, \"target\": y})\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Visualisation rapide\n",
        "plt.figure(figsize=(12, 3))\n",
        "plt.plot(df[\"timestamp\"], df[\"target\"])\n",
        "plt.title(\"Série temporelle (démo)\")\n",
        "plt.xlabel(\"timestamp\")\n",
        "plt.ylabel(\"target\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Partie 1 — Chronos-2 (Amazon)\n",
        "\n",
        "Chronos fournit une interface simple via `chronos-forecasting`.\n",
        "\n",
        "Nous allons :\n",
        "- mettre les données au format `id, timestamp, target`\n",
        "- charger `amazon/chronos-2`\n",
        "- produire un forecast probabiliste (quantiles)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Installation (Colab / local)\n",
        "!pip -q install -U chronos-forecasting matplotlib pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import torch\n",
        "from chronos import Chronos2Pipeline\n",
        "\n",
        "# Paramètres\n",
        "PRED_LEN = 48  # horizon de prévision (ex: 24, 48, 72)\n",
        "\n",
        "# Format attendu par Chronos: id / timestamp / target\n",
        "context_df = df.copy()\n",
        "context_df[\"id\"] = \"ts_1\"\n",
        "\n",
        "pipeline = Chronos2Pipeline.from_pretrained(\n",
        "    \"amazon/chronos-2\",\n",
        "    device_map=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        ")\n",
        "\n",
        "# Retourne un df contenant: timestamp, predictions, et des quantiles (ex: 0.1, 0.9)\n",
        "pred_df = pipeline.predict_df(\n",
        "    context_df,\n",
        "    prediction_length=PRED_LEN,\n",
        "    quantiles=[0.1, 0.5, 0.9],\n",
        ")\n",
        "\n",
        "pred_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Visualisation (historique + forecast)\n",
        "hist = context_df.set_index(\"timestamp\")[\"target\"].tail(200)\n",
        "pred = pred_df.set_index(\"timestamp\")\n",
        "\n",
        "plt.figure(figsize=(12, 3))\n",
        "plt.plot(hist.index, hist.values, label=\"historique\")\n",
        "plt.plot(pred.index, pred[\"predictions\"].values, label=\"prévision (médiane)\")\n",
        "plt.fill_between(pred.index, pred[\"0.1\"].values, pred[\"0.9\"].values, alpha=0.2, label=\"[0.1, 0.9]\")\n",
        "\n",
        "plt.title(\"Chronos-2 — prévision probabiliste\")\n",
        "plt.xlabel(\"timestamp\")\n",
        "plt.ylabel(\"target\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✅ **Exercices (Chronos)**\n",
        "\n",
        "1) Changez `PRED_LEN` (12, 24, 72) et observez.\n",
        "2) Remplacez la série synthétique par un CSV : colonnes `timestamp`, `target`.\n",
        "3) Essayez un modèle plus léger si besoin : `amazon/chronos-bolt-small`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Partie 2 — Moirai (Salesforce) via Uni2TS\n",
        "\n",
        "Moirai s'utilise via la librairie **Uni2TS** et **GluonTS**.\n",
        "\n",
        "Pipeline :\n",
        "- convertir `pandas.DataFrame` en `PandasDataset`\n",
        "- split train/test\n",
        "- charger le checkpoint Moirai depuis Hugging Face\n",
        "- créer un `predictor` et générer des forecasts\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Installation\n",
        "# (Si pip pose problème, essayez la version GitHub)\n",
        "!pip -q install -U uni2ts gluonts huggingface_hub matplotlib\n",
        "# !pip -q install -U \"git+https://github.com/SalesforceAIResearch/uni2ts.git\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from gluonts.dataset.pandas import PandasDataset\n",
        "from gluonts.dataset.split import split\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "from uni2ts.eval_util.plot import plot_single\n",
        "from uni2ts.model.moirai import MoiraiForecast\n",
        "\n",
        "SIZE = \"small\"     # {'small','base','large'} selon vos ressources\n",
        "PDT  = 48          # prediction length\n",
        "CTX  = 200         # context length\n",
        "PSZ  = \"auto\"      # {\"auto\", 8, 16, 32, 64, 128}\n",
        "BSZ  = 32          # batch size\n",
        "TEST = 96          # longueur du test\n",
        "\n",
        "# Wide DataFrame -> GluonTS dataset\n",
        "wide = df.set_index(\"timestamp\")[[\"target\"]]\n",
        "ds = PandasDataset(dict(wide))\n",
        "\n",
        "# Split train/test\n",
        "train, test_template = split(ds, offset=-TEST)\n",
        "\n",
        "# Rolling evaluation windows\n",
        "test_data = test_template.generate_instances(\n",
        "    prediction_length=PDT,\n",
        "    windows=max(1, TEST // PDT),\n",
        "    distance=PDT\n",
        ")\n",
        "\n",
        "# Télécharger le checkpoint\n",
        "ckpt_path = hf_hub_download(\n",
        "    repo_id=f\"Salesforce/moirai-R-{SIZE}\",\n",
        "    filename=\"model.ckpt\"\n",
        ")\n",
        "\n",
        "model = MoiraiForecast.load_from_checkpoint(\n",
        "    checkpoint_path=ckpt_path,\n",
        "    prediction_length=PDT,\n",
        "    context_length=CTX,\n",
        "    patch_size=PSZ,\n",
        "    num_samples=200,\n",
        "    target_dim=1,\n",
        "    feat_dynamic_real_dim=ds.num_feat_dynamic_real,\n",
        "    past_feat_dynamic_real_dim=ds.num_past_feat_dynamic_real,\n",
        "    map_location=\"cuda:0\" if torch.cuda.is_available() else \"cpu\",\n",
        ")\n",
        "\n",
        "predictor = model.create_predictor(batch_size=BSZ)\n",
        "forecasts = list(predictor.predict(test_data.input))\n",
        "\n",
        "# Afficher 1 exemple\n",
        "inp = next(iter(test_data.input))\n",
        "label = next(iter(test_data.label))\n",
        "forecast = forecasts[0]\n",
        "\n",
        "plot_single(inp, label, forecast, context_length=CTX, name=\"Moirai\", show_label=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✅ **Exercices (Moirai)**\n",
        "\n",
        "1) Essayez `SIZE='base'` si vous avez un GPU (sinon gardez `small`).\n",
        "2) Changez `CTX` et `PDT`.\n",
        "3) Comparez visuellement Chronos vs Moirai sur la même série (même horizon).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Partie 3 — Time-MoE (Mixture-of-Experts)\n",
        "\n",
        "Time-MoE est disponible via Hugging Face (`Maple728/TimeMoE-50M`, `TimeMoE-200M`, …) avec `trust_remote_code=True`.\n",
        "\n",
        "Le modèle opère sur des séquences numériques **normalisées**. Ici on fait une normalisation simple (z-score) sur le contexte.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Installation\n",
        "# Note: certains exemples Time-MoE recommandent transformers==4.40.1\n",
        "!pip -q install -U \"transformers==4.40.1\" accelerate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "MODEL_ID = \"Maple728/TimeMoE-50M\"  # petit modèle, plus léger\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    device_map=DEVICE,\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "\n",
        "context_length = 200\n",
        "prediction_length = 48\n",
        "\n",
        "series = df[\"target\"].values.astype(np.float32)\n",
        "context = series[-context_length:]\n",
        "\n",
        "# Normalisation simple\n",
        "mu = context.mean()\n",
        "sigma = context.std() + 1e-6\n",
        "context_norm = (context - mu) / sigma\n",
        "\n",
        "# Time-MoE attend typiquement un tensor [batch, context_len]\n",
        "x = torch.tensor(context_norm[None, :], dtype=torch.float32)\n",
        "x = x.to(model.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    out = model.generate(x, max_new_tokens=prediction_length)\n",
        "\n",
        "pred_norm = out[:, -prediction_length:].detach().cpu().numpy().squeeze()\n",
        "pred = pred_norm * sigma + mu\n",
        "\n",
        "future_idx = pd.date_range(df[\"timestamp\"].iloc[-1] + (df[\"timestamp\"].iloc[1]-df[\"timestamp\"].iloc[0]),\n",
        "                           periods=prediction_length, freq=\"H\")\n",
        "\n",
        "plt.figure(figsize=(12, 3))\n",
        "plt.plot(df[\"timestamp\"].tail(200), df[\"target\"].tail(200), label=\"historique\")\n",
        "plt.plot(future_idx, pred, label=\"prévision Time-MoE\")\n",
        "plt.title(\"Time-MoE — prévision (démo)\")\n",
        "plt.xlabel(\"timestamp\")\n",
        "plt.ylabel(\"target\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "✅ **Exercices (Time-MoE)**\n",
        "\n",
        "1) Essayez `MODEL_ID=\"Maple728/TimeMoE-200M\"` si vous avez un GPU.\n",
        "2) Testez d'autres normalisations : min-max, robust (median/IQR).\n",
        "3) Comparez les courbes Chronos / Moirai / Time-MoE sur la même figure.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Bonus — Comparaison rapide (overlay)\n",
        "\n",
        "On superpose Chronos (médiane) et Time-MoE si les variables existent.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "plt.figure(figsize=(12, 3))\n",
        "plt.plot(df[\"timestamp\"].tail(200), df[\"target\"].tail(200), label=\"historique\")\n",
        "\n",
        "# Chronos médiane\n",
        "try:\n",
        "    pred_chronos = pred_df.set_index(\"timestamp\")[\"predictions\"]\n",
        "    plt.plot(pred_chronos.index, pred_chronos.values, label=\"Chronos-2 (médiane)\")\n",
        "except Exception as e:\n",
        "    print(\"Chronos non disponible:\", e)\n",
        "\n",
        "# Time-MoE\n",
        "try:\n",
        "    plt.plot(future_idx, pred, label=\"Time-MoE\")\n",
        "except Exception as e:\n",
        "    print(\"Time-MoE non disponible:\", e)\n",
        "\n",
        "plt.title(\"Comparaison visuelle\")\n",
        "plt.xlabel(\"timestamp\")\n",
        "plt.ylabel(\"target\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fin\n",
        "\n",
        "Vous pouvez maintenant :\n",
        "\n",
        "- remplacer `df` par vos données réelles\n",
        "- tester d'autres horizons et contextes\n",
        "- ajouter des métriques (MAE, RMSE, MAPE, …) sur un vrai split train/test\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "name": "TP_TS_Foundation_Models.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}